#DATASET CONFIGURATION
dataset_params:
  text_cleaner: "basic_german_cleaners"
  enable_eos_bos_chars: false               # enable/disable beginning of sentence and end of sentence chars.
  num_loader_workers: 4                     # number of training data loader processes. Don't set it too big. 4-8 are good values.
  num_val_loader_workers: 4                 # number of evaluation data loader processes.
  batch_group_size: 0                       # Number of batches to shuffle after bucketing.
  min_seq_len: 6                            # DATASET-RELATED minimum text length to use in training
  max_seq_len: 140                          # DATASET-RELATED maximum text length
  output_path: "/media/alexander/LinuxFS/Documents/PycharmProjects/TTS/Trainings/" # Output Path for trained models

  # DATASETS
  datasets:                                 # List of datasets. They all merged and they get different speaker_ids.
    - name: "gothic_tts"
      path:  "/media/alexander/LinuxFS/SpeechData/GothicSpeech/NPC_Speech3/"
      meta_file_train: null
      meta_file_val: null
    


# VOCABULARY PARAMETERS
# If custom character set is not defined,
# default set in symbols.py is used
text_params:
 # CHARACTERS
 pad: "_"
 eos: "~"
 bos: "^"
 characters: "ABCDEFGHIJKLMNOPQRSTUVWXYZÄÖÜabcdefghijklmnopqrstuvwxyzäöüß!'(),-.:;? "
 punctuations: "!'(),-.:;?"
 phonemes: "iyɨʉɯuɪʏʊeøɘəɵɤoɛœɜɞʌɔæɐaɶɑɒᵻʘɓǀɗǃʄǂɠǁʛpbtdʈɖcɟkɡqɢʔɴŋɲɳnɱmʙrʀⱱɾɽɸβfvθðszʃʒʂʐçʝxɣχʁħʕhɦɬɮʋɹɻjɰlɭʎʟˈˌːˑʍwɥʜʢʡɕʑɺɧɚ˞ɫ"

 # PHONEMES
 use_phonemes: false,                    # Use phonemes instead of raw characters. It is suggested for better pronounciation.
 phoneme_cache_path: "gothic_phonemes"   # Phoneme computation is slow, therefore, it caches results in the given folder.
 phoneme_language: "de"                  # Depending on your target language, pick one from  https:#github.com/bootphon/phonemizer#languages


# TENSORBOARD and LOGGING
logging_params:
  print_step: 25                # Number of steps to log traning on console.
  print_eval: false             # If True, it prints loss values in evalulation.
  save_step: 10000              # Number of training steps expected to save traninpg stats and checkpoints.
  checkpoint: true              # If true, it saves checkpoints per save_step
  tb_model_param_stats: false   # true, plots param stats per layer on tensorboard. Might be memory consuming, but good for debugging.